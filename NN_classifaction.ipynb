{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first dataset (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  Insulin   BMI  \\\n",
       "0            6      148             72        0  33.6   \n",
       "1            1       85             66        0  26.6   \n",
       "2            8      183             64        0  23.3   \n",
       "3            1       89             66       94  28.1   \n",
       "4            0      137             40      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "del data['SkinThickness']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check for outliears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  Insulin   BMI  \\\n",
       "0            6      148             72        0  33.6   \n",
       "1            1       85             66        0  26.6   \n",
       "2            8      183             64        0  23.3   \n",
       "3            1       89             66       94  28.1   \n",
       "5            5      116             74        0  25.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "5                     0.201   30        0  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_outliers(col):\n",
    "    q1 = col.quantile(.25)\n",
    "    q3 = col.quantile(.75)\n",
    "    IQR = q3 - q1\n",
    "    ll = q1 - (1.5*IQR)\n",
    "    ul = q3 + (1.5*IQR)\n",
    "    upper_outliers = col[col > ul].index.tolist()\n",
    "    lower_outliers = col[col < ll].index.tolist()\n",
    "    bad_indices = list(set(upper_outliers + lower_outliers))\n",
    "    return(bad_indices,lower_outliers,upper_outliers)\n",
    "\n",
    "bad_indexes = []\n",
    "for col in data.columns:\n",
    "    if data[col].dtype in [\"int64\",\"float64\"]:\n",
    "        BI,lower,upper = find_outliers(data[col])\n",
    "        bad_indexes.append(BI)\n",
    "        data.drop(upper, inplace = True)\n",
    "        data.drop(lower, inplace = True)\n",
    "         \n",
    "\n",
    "bad_indexes = set(list(np.concatenate(bad_indexes).flat))\n",
    "print(len(bad_indexes))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "x = data[:, 0:6]\n",
    "y = data[:,7]\n",
    "y = y.reshape(-1,1)\n",
    "normalized_data = preprocessing.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(normalized_data,y ,random_state=104, train_size=0.8,test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivate=False):\n",
    "    if derivate:\n",
    "        return(np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "    else:\n",
    "        return (1/(np.exp(-x)+1))    \n",
    "\n",
    "def softmax(x,derivate = False):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    if derivate:\n",
    "        return (exp_element/np.sum(exp_element,axis=0)*(1-exp_element/np.sum(exp_element,axis=0)))    \n",
    "    else:\n",
    "        return (exp_element/np.sum(exp_element,axis=0))\n",
    "\n",
    "def init(x,y):\n",
    "    layer=np.random.uniform(size=(x,y)) #/ np.sqrt(x*y)\n",
    "    return layer\n",
    "\n",
    "def mean_squared_error(y, y_pred,derivate = False):\n",
    "    if derivate:\n",
    "        return(y_pred - y)\n",
    "    else:\n",
    "        return sum((y-y_pred)**2) / len(y)\n",
    "\n",
    "def cross_entropy(y,y_pre):\n",
    "    loss=-np.sum(y*np.log(y_pre))\n",
    "    return loss/float(y_pre.shape[0])\n",
    "\n",
    "w1 = init(6,3)\n",
    "w2 = init(3,1)\n",
    "\n",
    "def forward_backward_pass(x,y,lr):\n",
    "    # forward\n",
    "    Z1 = x.dot(w1) \n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 =A1.dot(w2) \n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    #backward\n",
    "    # output layer\n",
    "    \n",
    "    for i in range(y.shape[0]):\n",
    "        delta = (y[i]-A2[i]) * sigmoid(A2[i],True)\n",
    "        w2_change_rate = lr * delta * A1[i]\n",
    "\n",
    "    w2_change_rate = w2_change_rate.reshape(3,1)\n",
    "    w2_new = w2 - w2_change_rate\n",
    "    \n",
    "    # hidden layer\n",
    "    for i in range(y.shape[0]):\n",
    "        delta_hidden = np.dot(delta , w2_new.T)  * sigmoid(A1[i],True)\n",
    "        delta_hidden = delta_hidden.reshape(3,1)\n",
    "        x1 = x[i].reshape(1,6)\n",
    "        w1_change_rate = lr * np.dot(delta_hidden ,x1)\n",
    "    \n",
    "    w1_new = w1 - w1_change_rate.T\n",
    "    \n",
    "    return(A2,w1_new,w2_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model on the frist data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0th epoch: train accuracy: 58.000 \n",
      "For 0th epoch: test accuracy: 72.656 \n",
      "For 0th epoch: train loss: 0.200 \n",
      "For 0th epoch: test loss: 1.327 \n",
      "For 1th epoch: train accuracy: 71.000 \n",
      "For 1th epoch: test accuracy: 72.656 \n",
      "For 1th epoch: train loss: 0.138 \n",
      "For 1th epoch: test loss: 1.327 \n",
      "For 2th epoch: train accuracy: 64.000 \n",
      "For 2th epoch: test accuracy: 72.656 \n",
      "For 2th epoch: train loss: 0.171 \n",
      "For 2th epoch: test loss: 1.327 \n",
      "For 3th epoch: train accuracy: 70.000 \n",
      "For 3th epoch: test accuracy: 72.656 \n",
      "For 3th epoch: train loss: 0.143 \n",
      "For 3th epoch: test loss: 1.327 \n",
      "For 4th epoch: train accuracy: 73.000 \n",
      "For 4th epoch: test accuracy: 72.656 \n",
      "For 4th epoch: train loss: 0.128 \n",
      "For 4th epoch: test loss: 1.327 \n",
      "For 5th epoch: train accuracy: 68.000 \n",
      "For 5th epoch: test accuracy: 72.656 \n",
      "For 5th epoch: train loss: 0.153 \n",
      "For 5th epoch: test loss: 1.327 \n",
      "For 6th epoch: train accuracy: 77.000 \n",
      "For 6th epoch: test accuracy: 72.656 \n",
      "For 6th epoch: train loss: 0.109 \n",
      "For 6th epoch: test loss: 1.327 \n",
      "For 7th epoch: train accuracy: 67.000 \n",
      "For 7th epoch: test accuracy: 72.656 \n",
      "For 7th epoch: train loss: 0.157 \n",
      "For 7th epoch: test loss: 1.327 \n",
      "For 8th epoch: train accuracy: 71.000 \n",
      "For 8th epoch: test accuracy: 72.656 \n",
      "For 8th epoch: train loss: 0.138 \n",
      "For 8th epoch: test loss: 1.327 \n",
      "For 9th epoch: train accuracy: 64.000 \n",
      "For 9th epoch: test accuracy: 72.656 \n",
      "For 9th epoch: train loss: 0.171 \n",
      "For 9th epoch: test loss: 1.327 \n",
      "For 10th epoch: train accuracy: 71.000 \n",
      "For 10th epoch: test accuracy: 72.656 \n",
      "For 10th epoch: train loss: 0.138 \n",
      "For 10th epoch: test loss: 1.327 \n",
      "For 11th epoch: train accuracy: 70.000 \n",
      "For 11th epoch: test accuracy: 72.656 \n",
      "For 11th epoch: train loss: 0.143 \n",
      "For 11th epoch: test loss: 1.327 \n",
      "For 12th epoch: train accuracy: 61.000 \n",
      "For 12th epoch: test accuracy: 72.656 \n",
      "For 12th epoch: train loss: 0.185 \n",
      "For 12th epoch: test loss: 1.327 \n",
      "For 13th epoch: train accuracy: 67.000 \n",
      "For 13th epoch: test accuracy: 72.656 \n",
      "For 13th epoch: train loss: 0.157 \n",
      "For 13th epoch: test loss: 1.327 \n",
      "For 14th epoch: train accuracy: 64.000 \n",
      "For 14th epoch: test accuracy: 72.656 \n",
      "For 14th epoch: train loss: 0.171 \n",
      "For 14th epoch: test loss: 1.327 \n",
      "For 15th epoch: train accuracy: 68.000 \n",
      "For 15th epoch: test accuracy: 72.656 \n",
      "For 15th epoch: train loss: 0.152 \n",
      "For 15th epoch: test loss: 1.327 \n",
      "For 16th epoch: train accuracy: 64.000 \n",
      "For 16th epoch: test accuracy: 72.656 \n",
      "For 16th epoch: train loss: 0.171 \n",
      "For 16th epoch: test loss: 1.327 \n",
      "For 17th epoch: train accuracy: 61.000 \n",
      "For 17th epoch: test accuracy: 72.656 \n",
      "For 17th epoch: train loss: 0.185 \n",
      "For 17th epoch: test loss: 1.327 \n",
      "For 18th epoch: train accuracy: 60.000 \n",
      "For 18th epoch: test accuracy: 72.656 \n",
      "For 18th epoch: train loss: 0.190 \n",
      "For 18th epoch: test loss: 1.327 \n",
      "For 19th epoch: train accuracy: 69.000 \n",
      "For 19th epoch: test accuracy: 72.656 \n",
      "For 19th epoch: train loss: 0.148 \n",
      "For 19th epoch: test loss: 1.327 \n",
      "For 20th epoch: train accuracy: 72.000 \n",
      "For 20th epoch: test accuracy: 72.656 \n",
      "For 20th epoch: train loss: 0.133 \n",
      "For 20th epoch: test loss: 1.327 \n",
      "For 21th epoch: train accuracy: 74.000 \n",
      "For 21th epoch: test accuracy: 72.656 \n",
      "For 21th epoch: train loss: 0.124 \n",
      "For 21th epoch: test loss: 1.327 \n",
      "For 22th epoch: train accuracy: 66.000 \n",
      "For 22th epoch: test accuracy: 72.656 \n",
      "For 22th epoch: train loss: 0.162 \n",
      "For 22th epoch: test loss: 1.327 \n",
      "For 23th epoch: train accuracy: 66.000 \n",
      "For 23th epoch: test accuracy: 72.656 \n",
      "For 23th epoch: train loss: 0.162 \n",
      "For 23th epoch: test loss: 1.327 \n",
      "For 24th epoch: train accuracy: 61.000 \n",
      "For 24th epoch: test accuracy: 72.656 \n",
      "For 24th epoch: train loss: 0.185 \n",
      "For 24th epoch: test loss: 1.327 \n",
      "For 25th epoch: train accuracy: 73.000 \n",
      "For 25th epoch: test accuracy: 72.656 \n",
      "For 25th epoch: train loss: 0.128 \n",
      "For 25th epoch: test loss: 1.327 \n",
      "For 26th epoch: train accuracy: 61.000 \n",
      "For 26th epoch: test accuracy: 72.656 \n",
      "For 26th epoch: train loss: 0.186 \n",
      "For 26th epoch: test loss: 1.327 \n",
      "For 27th epoch: train accuracy: 71.000 \n",
      "For 27th epoch: test accuracy: 72.656 \n",
      "For 27th epoch: train loss: 0.138 \n",
      "For 27th epoch: test loss: 1.327 \n",
      "For 28th epoch: train accuracy: 66.000 \n",
      "For 28th epoch: test accuracy: 72.656 \n",
      "For 28th epoch: train loss: 0.161 \n",
      "For 28th epoch: test loss: 1.327 \n",
      "For 29th epoch: train accuracy: 65.000 \n",
      "For 29th epoch: test accuracy: 72.656 \n",
      "For 29th epoch: train loss: 0.166 \n",
      "For 29th epoch: test loss: 1.327 \n",
      "For 30th epoch: train accuracy: 68.000 \n",
      "For 30th epoch: test accuracy: 72.656 \n",
      "For 30th epoch: train loss: 0.152 \n",
      "For 30th epoch: test loss: 1.327 \n",
      "For 31th epoch: train accuracy: 63.000 \n",
      "For 31th epoch: test accuracy: 72.656 \n",
      "For 31th epoch: train loss: 0.176 \n",
      "For 31th epoch: test loss: 1.327 \n",
      "For 32th epoch: train accuracy: 74.000 \n",
      "For 32th epoch: test accuracy: 72.656 \n",
      "For 32th epoch: train loss: 0.124 \n",
      "For 32th epoch: test loss: 1.327 \n",
      "For 33th epoch: train accuracy: 78.000 \n",
      "For 33th epoch: test accuracy: 72.656 \n",
      "For 33th epoch: train loss: 0.105 \n",
      "For 33th epoch: test loss: 1.327 \n",
      "For 34th epoch: train accuracy: 73.000 \n",
      "For 34th epoch: test accuracy: 72.656 \n",
      "For 34th epoch: train loss: 0.129 \n",
      "For 34th epoch: test loss: 1.327 \n",
      "For 35th epoch: train accuracy: 69.000 \n",
      "For 35th epoch: test accuracy: 72.656 \n",
      "For 35th epoch: train loss: 0.147 \n",
      "For 35th epoch: test loss: 1.327 \n",
      "For 36th epoch: train accuracy: 70.000 \n",
      "For 36th epoch: test accuracy: 72.656 \n",
      "For 36th epoch: train loss: 0.142 \n",
      "For 36th epoch: test loss: 1.327 \n",
      "For 37th epoch: train accuracy: 73.000 \n",
      "For 37th epoch: test accuracy: 72.656 \n",
      "For 37th epoch: train loss: 0.129 \n",
      "For 37th epoch: test loss: 1.327 \n",
      "For 38th epoch: train accuracy: 74.000 \n",
      "For 38th epoch: test accuracy: 72.656 \n",
      "For 38th epoch: train loss: 0.124 \n",
      "For 38th epoch: test loss: 1.327 \n",
      "For 39th epoch: train accuracy: 72.000 \n",
      "For 39th epoch: test accuracy: 72.656 \n",
      "For 39th epoch: train loss: 0.133 \n",
      "For 39th epoch: test loss: 1.327 \n",
      "For 40th epoch: train accuracy: 75.000 \n",
      "For 40th epoch: test accuracy: 72.656 \n",
      "For 40th epoch: train loss: 0.119 \n",
      "For 40th epoch: test loss: 1.327 \n",
      "For 41th epoch: train accuracy: 70.000 \n",
      "For 41th epoch: test accuracy: 72.656 \n",
      "For 41th epoch: train loss: 0.143 \n",
      "For 41th epoch: test loss: 1.327 \n",
      "For 42th epoch: train accuracy: 71.000 \n",
      "For 42th epoch: test accuracy: 72.656 \n",
      "For 42th epoch: train loss: 0.138 \n",
      "For 42th epoch: test loss: 1.327 \n",
      "For 43th epoch: train accuracy: 59.000 \n",
      "For 43th epoch: test accuracy: 72.656 \n",
      "For 43th epoch: train loss: 0.195 \n",
      "For 43th epoch: test loss: 1.327 \n",
      "For 44th epoch: train accuracy: 61.000 \n",
      "For 44th epoch: test accuracy: 72.656 \n",
      "For 44th epoch: train loss: 0.185 \n",
      "For 44th epoch: test loss: 1.327 \n",
      "For 45th epoch: train accuracy: 77.000 \n",
      "For 45th epoch: test accuracy: 72.656 \n",
      "For 45th epoch: train loss: 0.109 \n",
      "For 45th epoch: test loss: 1.327 \n",
      "For 46th epoch: train accuracy: 68.000 \n",
      "For 46th epoch: test accuracy: 72.656 \n",
      "For 46th epoch: train loss: 0.153 \n",
      "For 46th epoch: test loss: 1.327 \n",
      "For 47th epoch: train accuracy: 70.000 \n",
      "For 47th epoch: test accuracy: 72.656 \n",
      "For 47th epoch: train loss: 0.143 \n",
      "For 47th epoch: test loss: 1.327 \n",
      "For 48th epoch: train accuracy: 70.000 \n",
      "For 48th epoch: test accuracy: 72.656 \n",
      "For 48th epoch: train loss: 0.143 \n",
      "For 48th epoch: test loss: 1.327 \n",
      "For 49th epoch: train accuracy: 64.000 \n",
      "For 49th epoch: test accuracy: 72.656 \n",
      "For 49th epoch: train loss: 0.172 \n",
      "For 49th epoch: test loss: 1.327 \n",
      "For 50th epoch: train accuracy: 70.000 \n",
      "For 50th epoch: test accuracy: 72.656 \n",
      "For 50th epoch: train loss: 0.143 \n",
      "For 50th epoch: test loss: 1.327 \n",
      "For 51th epoch: train accuracy: 58.000 \n",
      "For 51th epoch: test accuracy: 72.656 \n",
      "For 51th epoch: train loss: 0.200 \n",
      "For 51th epoch: test loss: 1.327 \n",
      "For 52th epoch: train accuracy: 68.000 \n",
      "For 52th epoch: test accuracy: 72.656 \n",
      "For 52th epoch: train loss: 0.152 \n",
      "For 52th epoch: test loss: 1.327 \n",
      "For 53th epoch: train accuracy: 66.000 \n",
      "For 53th epoch: test accuracy: 72.656 \n",
      "For 53th epoch: train loss: 0.162 \n",
      "For 53th epoch: test loss: 1.327 \n",
      "For 54th epoch: train accuracy: 60.000 \n",
      "For 54th epoch: test accuracy: 72.656 \n",
      "For 54th epoch: train loss: 0.190 \n",
      "For 54th epoch: test loss: 1.327 \n",
      "For 55th epoch: train accuracy: 70.000 \n",
      "For 55th epoch: test accuracy: 72.656 \n",
      "For 55th epoch: train loss: 0.142 \n",
      "For 55th epoch: test loss: 1.327 \n",
      "For 56th epoch: train accuracy: 66.000 \n",
      "For 56th epoch: test accuracy: 72.656 \n",
      "For 56th epoch: train loss: 0.162 \n",
      "For 56th epoch: test loss: 1.327 \n",
      "For 57th epoch: train accuracy: 77.000 \n",
      "For 57th epoch: test accuracy: 72.656 \n",
      "For 57th epoch: train loss: 0.110 \n",
      "For 57th epoch: test loss: 1.327 \n",
      "For 58th epoch: train accuracy: 67.000 \n",
      "For 58th epoch: test accuracy: 72.656 \n",
      "For 58th epoch: train loss: 0.157 \n",
      "For 58th epoch: test loss: 1.327 \n",
      "For 59th epoch: train accuracy: 61.000 \n",
      "For 59th epoch: test accuracy: 72.656 \n",
      "For 59th epoch: train loss: 0.186 \n",
      "For 59th epoch: test loss: 1.327 \n",
      "For 60th epoch: train accuracy: 65.000 \n",
      "For 60th epoch: test accuracy: 72.656 \n",
      "For 60th epoch: train loss: 0.166 \n",
      "For 60th epoch: test loss: 1.327 \n",
      "For 61th epoch: train accuracy: 81.000 \n",
      "For 61th epoch: test accuracy: 72.656 \n",
      "For 61th epoch: train loss: 0.091 \n",
      "For 61th epoch: test loss: 1.327 \n",
      "For 62th epoch: train accuracy: 75.000 \n",
      "For 62th epoch: test accuracy: 72.656 \n",
      "For 62th epoch: train loss: 0.119 \n",
      "For 62th epoch: test loss: 1.327 \n",
      "For 63th epoch: train accuracy: 70.000 \n",
      "For 63th epoch: test accuracy: 72.656 \n",
      "For 63th epoch: train loss: 0.142 \n",
      "For 63th epoch: test loss: 1.327 \n",
      "For 64th epoch: train accuracy: 69.000 \n",
      "For 64th epoch: test accuracy: 72.656 \n",
      "For 64th epoch: train loss: 0.148 \n",
      "For 64th epoch: test loss: 1.327 \n",
      "For 65th epoch: train accuracy: 68.000 \n",
      "For 65th epoch: test accuracy: 72.656 \n",
      "For 65th epoch: train loss: 0.152 \n",
      "For 65th epoch: test loss: 1.327 \n",
      "For 66th epoch: train accuracy: 70.000 \n",
      "For 66th epoch: test accuracy: 72.656 \n",
      "For 66th epoch: train loss: 0.143 \n",
      "For 66th epoch: test loss: 1.327 \n",
      "For 67th epoch: train accuracy: 71.000 \n",
      "For 67th epoch: test accuracy: 72.656 \n",
      "For 67th epoch: train loss: 0.138 \n",
      "For 67th epoch: test loss: 1.327 \n",
      "For 68th epoch: train accuracy: 75.000 \n",
      "For 68th epoch: test accuracy: 72.656 \n",
      "For 68th epoch: train loss: 0.119 \n",
      "For 68th epoch: test loss: 1.327 \n",
      "For 69th epoch: train accuracy: 69.000 \n",
      "For 69th epoch: test accuracy: 72.656 \n",
      "For 69th epoch: train loss: 0.148 \n",
      "For 69th epoch: test loss: 1.327 \n",
      "For 70th epoch: train accuracy: 72.000 \n",
      "For 70th epoch: test accuracy: 72.656 \n",
      "For 70th epoch: train loss: 0.133 \n",
      "For 70th epoch: test loss: 1.327 \n",
      "For 71th epoch: train accuracy: 70.000 \n",
      "For 71th epoch: test accuracy: 72.656 \n",
      "For 71th epoch: train loss: 0.143 \n",
      "For 71th epoch: test loss: 1.327 \n",
      "For 72th epoch: train accuracy: 65.000 \n",
      "For 72th epoch: test accuracy: 72.656 \n",
      "For 72th epoch: train loss: 0.167 \n",
      "For 72th epoch: test loss: 1.327 \n",
      "For 73th epoch: train accuracy: 61.000 \n",
      "For 73th epoch: test accuracy: 72.656 \n",
      "For 73th epoch: train loss: 0.186 \n",
      "For 73th epoch: test loss: 1.327 \n",
      "For 74th epoch: train accuracy: 72.000 \n",
      "For 74th epoch: test accuracy: 72.656 \n",
      "For 74th epoch: train loss: 0.133 \n",
      "For 74th epoch: test loss: 1.327 \n",
      "For 75th epoch: train accuracy: 69.000 \n",
      "For 75th epoch: test accuracy: 72.656 \n",
      "For 75th epoch: train loss: 0.148 \n",
      "For 75th epoch: test loss: 1.327 \n",
      "For 76th epoch: train accuracy: 72.000 \n",
      "For 76th epoch: test accuracy: 72.656 \n",
      "For 76th epoch: train loss: 0.133 \n",
      "For 76th epoch: test loss: 1.327 \n",
      "For 77th epoch: train accuracy: 59.000 \n",
      "For 77th epoch: test accuracy: 72.656 \n",
      "For 77th epoch: train loss: 0.195 \n",
      "For 77th epoch: test loss: 1.327 \n",
      "For 78th epoch: train accuracy: 68.000 \n",
      "For 78th epoch: test accuracy: 72.656 \n",
      "For 78th epoch: train loss: 0.153 \n",
      "For 78th epoch: test loss: 1.327 \n",
      "For 79th epoch: train accuracy: 65.000 \n",
      "For 79th epoch: test accuracy: 72.656 \n",
      "For 79th epoch: train loss: 0.166 \n",
      "For 79th epoch: test loss: 1.327 \n",
      "For 80th epoch: train accuracy: 67.000 \n",
      "For 80th epoch: test accuracy: 72.656 \n",
      "For 80th epoch: train loss: 0.157 \n",
      "For 80th epoch: test loss: 1.327 \n",
      "For 81th epoch: train accuracy: 68.000 \n",
      "For 81th epoch: test accuracy: 72.656 \n",
      "For 81th epoch: train loss: 0.152 \n",
      "For 81th epoch: test loss: 1.327 \n",
      "For 82th epoch: train accuracy: 77.000 \n",
      "For 82th epoch: test accuracy: 72.656 \n",
      "For 82th epoch: train loss: 0.110 \n",
      "For 82th epoch: test loss: 1.327 \n",
      "For 83th epoch: train accuracy: 65.000 \n",
      "For 83th epoch: test accuracy: 72.656 \n",
      "For 83th epoch: train loss: 0.167 \n",
      "For 83th epoch: test loss: 1.327 \n",
      "For 84th epoch: train accuracy: 66.000 \n",
      "For 84th epoch: test accuracy: 72.656 \n",
      "For 84th epoch: train loss: 0.162 \n",
      "For 84th epoch: test loss: 1.327 \n",
      "For 85th epoch: train accuracy: 72.000 \n",
      "For 85th epoch: test accuracy: 72.656 \n",
      "For 85th epoch: train loss: 0.133 \n",
      "For 85th epoch: test loss: 1.327 \n",
      "For 86th epoch: train accuracy: 67.000 \n",
      "For 86th epoch: test accuracy: 72.656 \n",
      "For 86th epoch: train loss: 0.157 \n",
      "For 86th epoch: test loss: 1.327 \n",
      "For 87th epoch: train accuracy: 67.000 \n",
      "For 87th epoch: test accuracy: 72.656 \n",
      "For 87th epoch: train loss: 0.157 \n",
      "For 87th epoch: test loss: 1.327 \n",
      "For 88th epoch: train accuracy: 72.000 \n",
      "For 88th epoch: test accuracy: 72.656 \n",
      "For 88th epoch: train loss: 0.133 \n",
      "For 88th epoch: test loss: 1.327 \n",
      "For 89th epoch: train accuracy: 59.000 \n",
      "For 89th epoch: test accuracy: 72.656 \n",
      "For 89th epoch: train loss: 0.195 \n",
      "For 89th epoch: test loss: 1.327 \n",
      "For 90th epoch: train accuracy: 61.000 \n",
      "For 90th epoch: test accuracy: 72.656 \n",
      "For 90th epoch: train loss: 0.186 \n",
      "For 90th epoch: test loss: 1.327 \n",
      "For 91th epoch: train accuracy: 61.000 \n",
      "For 91th epoch: test accuracy: 72.656 \n",
      "For 91th epoch: train loss: 0.186 \n",
      "For 91th epoch: test loss: 1.327 \n",
      "For 92th epoch: train accuracy: 63.000 \n",
      "For 92th epoch: test accuracy: 72.656 \n",
      "For 92th epoch: train loss: 0.176 \n",
      "For 92th epoch: test loss: 1.327 \n",
      "For 93th epoch: train accuracy: 64.000 \n",
      "For 93th epoch: test accuracy: 72.656 \n",
      "For 93th epoch: train loss: 0.171 \n",
      "For 93th epoch: test loss: 1.327 \n",
      "For 94th epoch: train accuracy: 68.000 \n",
      "For 94th epoch: test accuracy: 72.656 \n",
      "For 94th epoch: train loss: 0.152 \n",
      "For 94th epoch: test loss: 1.327 \n",
      "For 95th epoch: train accuracy: 77.000 \n",
      "For 95th epoch: test accuracy: 72.656 \n",
      "For 95th epoch: train loss: 0.110 \n",
      "For 95th epoch: test loss: 1.327 \n",
      "For 96th epoch: train accuracy: 72.000 \n",
      "For 96th epoch: test accuracy: 72.656 \n",
      "For 96th epoch: train loss: 0.133 \n",
      "For 96th epoch: test loss: 1.327 \n",
      "For 97th epoch: train accuracy: 69.000 \n",
      "For 97th epoch: test accuracy: 72.656 \n",
      "For 97th epoch: train loss: 0.147 \n",
      "For 97th epoch: test loss: 1.327 \n",
      "For 98th epoch: train accuracy: 71.000 \n",
      "For 98th epoch: test accuracy: 72.656 \n",
      "For 98th epoch: train loss: 0.138 \n",
      "For 98th epoch: test loss: 1.327 \n",
      "For 99th epoch: train accuracy: 70.000 \n",
      "For 99th epoch: test accuracy: 72.656 \n",
      "For 99th epoch: train loss: 0.143 \n",
      "For 99th epoch: test loss: 1.327 \n",
      "For 100th epoch: train accuracy: 70.000 \n",
      "For 100th epoch: test accuracy: 72.656 \n",
      "For 100th epoch: train loss: 0.143 \n",
      "For 100th epoch: test loss: 1.327 \n",
      "For 101th epoch: train accuracy: 67.000 \n",
      "For 101th epoch: test accuracy: 72.656 \n",
      "For 101th epoch: train loss: 0.157 \n",
      "For 101th epoch: test loss: 1.327 \n",
      "For 102th epoch: train accuracy: 64.000 \n",
      "For 102th epoch: test accuracy: 72.656 \n",
      "For 102th epoch: train loss: 0.171 \n",
      "For 102th epoch: test loss: 1.327 \n",
      "For 103th epoch: train accuracy: 70.000 \n",
      "For 103th epoch: test accuracy: 72.656 \n",
      "For 103th epoch: train loss: 0.143 \n",
      "For 103th epoch: test loss: 1.327 \n",
      "For 104th epoch: train accuracy: 66.000 \n",
      "For 104th epoch: test accuracy: 72.656 \n",
      "For 104th epoch: train loss: 0.162 \n",
      "For 104th epoch: test loss: 1.327 \n",
      "For 105th epoch: train accuracy: 76.000 \n",
      "For 105th epoch: test accuracy: 72.656 \n",
      "For 105th epoch: train loss: 0.114 \n",
      "For 105th epoch: test loss: 1.327 \n",
      "For 106th epoch: train accuracy: 66.000 \n",
      "For 106th epoch: test accuracy: 72.656 \n",
      "For 106th epoch: train loss: 0.162 \n",
      "For 106th epoch: test loss: 1.327 \n",
      "For 107th epoch: train accuracy: 65.000 \n",
      "For 107th epoch: test accuracy: 72.656 \n",
      "For 107th epoch: train loss: 0.166 \n",
      "For 107th epoch: test loss: 1.327 \n",
      "For 108th epoch: train accuracy: 70.000 \n",
      "For 108th epoch: test accuracy: 72.656 \n",
      "For 108th epoch: train loss: 0.143 \n",
      "For 108th epoch: test loss: 1.327 \n",
      "For 109th epoch: train accuracy: 63.000 \n",
      "For 109th epoch: test accuracy: 72.656 \n",
      "For 109th epoch: train loss: 0.176 \n",
      "For 109th epoch: test loss: 1.327 \n",
      "For 110th epoch: train accuracy: 70.000 \n",
      "For 110th epoch: test accuracy: 72.656 \n",
      "For 110th epoch: train loss: 0.143 \n",
      "For 110th epoch: test loss: 1.327 \n",
      "For 111th epoch: train accuracy: 62.000 \n",
      "For 111th epoch: test accuracy: 72.656 \n",
      "For 111th epoch: train loss: 0.181 \n",
      "For 111th epoch: test loss: 1.327 \n",
      "For 112th epoch: train accuracy: 66.000 \n",
      "For 112th epoch: test accuracy: 72.656 \n",
      "For 112th epoch: train loss: 0.162 \n",
      "For 112th epoch: test loss: 1.327 \n",
      "For 113th epoch: train accuracy: 69.000 \n",
      "For 113th epoch: test accuracy: 72.656 \n",
      "For 113th epoch: train loss: 0.147 \n",
      "For 113th epoch: test loss: 1.327 \n",
      "For 114th epoch: train accuracy: 64.000 \n",
      "For 114th epoch: test accuracy: 72.656 \n",
      "For 114th epoch: train loss: 0.171 \n",
      "For 114th epoch: test loss: 1.327 \n",
      "For 115th epoch: train accuracy: 79.000 \n",
      "For 115th epoch: test accuracy: 72.656 \n",
      "For 115th epoch: train loss: 0.100 \n",
      "For 115th epoch: test loss: 1.327 \n",
      "For 116th epoch: train accuracy: 73.000 \n",
      "For 116th epoch: test accuracy: 72.656 \n",
      "For 116th epoch: train loss: 0.129 \n",
      "For 116th epoch: test loss: 1.327 \n",
      "For 117th epoch: train accuracy: 70.000 \n",
      "For 117th epoch: test accuracy: 72.656 \n",
      "For 117th epoch: train loss: 0.143 \n",
      "For 117th epoch: test loss: 1.327 \n",
      "For 118th epoch: train accuracy: 70.000 \n",
      "For 118th epoch: test accuracy: 72.656 \n",
      "For 118th epoch: train loss: 0.143 \n",
      "For 118th epoch: test loss: 1.327 \n",
      "For 119th epoch: train accuracy: 62.000 \n",
      "For 119th epoch: test accuracy: 72.656 \n",
      "For 119th epoch: train loss: 0.180 \n",
      "For 119th epoch: test loss: 1.327 \n",
      "For 120th epoch: train accuracy: 67.000 \n",
      "For 120th epoch: test accuracy: 72.656 \n",
      "For 120th epoch: train loss: 0.157 \n",
      "For 120th epoch: test loss: 1.327 \n",
      "For 121th epoch: train accuracy: 69.000 \n",
      "For 121th epoch: test accuracy: 72.656 \n",
      "For 121th epoch: train loss: 0.147 \n",
      "For 121th epoch: test loss: 1.327 \n",
      "For 122th epoch: train accuracy: 66.000 \n",
      "For 122th epoch: test accuracy: 72.656 \n",
      "For 122th epoch: train loss: 0.162 \n",
      "For 122th epoch: test loss: 1.327 \n",
      "For 123th epoch: train accuracy: 70.000 \n",
      "For 123th epoch: test accuracy: 72.656 \n",
      "For 123th epoch: train loss: 0.143 \n",
      "For 123th epoch: test loss: 1.327 \n",
      "For 124th epoch: train accuracy: 65.000 \n",
      "For 124th epoch: test accuracy: 72.656 \n",
      "For 124th epoch: train loss: 0.167 \n",
      "For 124th epoch: test loss: 1.327 \n",
      "For 125th epoch: train accuracy: 54.000 \n",
      "For 125th epoch: test accuracy: 72.656 \n",
      "For 125th epoch: train loss: 0.219 \n",
      "For 125th epoch: test loss: 1.327 \n",
      "For 126th epoch: train accuracy: 75.000 \n",
      "For 126th epoch: test accuracy: 72.656 \n",
      "For 126th epoch: train loss: 0.119 \n",
      "For 126th epoch: test loss: 1.327 \n",
      "For 127th epoch: train accuracy: 77.000 \n",
      "For 127th epoch: test accuracy: 72.656 \n",
      "For 127th epoch: train loss: 0.110 \n",
      "For 127th epoch: test loss: 1.327 \n",
      "For 128th epoch: train accuracy: 59.000 \n",
      "For 128th epoch: test accuracy: 72.656 \n",
      "For 128th epoch: train loss: 0.195 \n",
      "For 128th epoch: test loss: 1.327 \n",
      "For 129th epoch: train accuracy: 71.000 \n",
      "For 129th epoch: test accuracy: 72.656 \n",
      "For 129th epoch: train loss: 0.138 \n",
      "For 129th epoch: test loss: 1.327 \n",
      "For 130th epoch: train accuracy: 69.000 \n",
      "For 130th epoch: test accuracy: 72.656 \n",
      "For 130th epoch: train loss: 0.148 \n",
      "For 130th epoch: test loss: 1.327 \n",
      "For 131th epoch: train accuracy: 69.000 \n",
      "For 131th epoch: test accuracy: 72.656 \n",
      "For 131th epoch: train loss: 0.147 \n",
      "For 131th epoch: test loss: 1.327 \n",
      "For 132th epoch: train accuracy: 64.000 \n",
      "For 132th epoch: test accuracy: 72.656 \n",
      "For 132th epoch: train loss: 0.172 \n",
      "For 132th epoch: test loss: 1.327 \n",
      "For 133th epoch: train accuracy: 67.000 \n",
      "For 133th epoch: test accuracy: 72.656 \n",
      "For 133th epoch: train loss: 0.157 \n",
      "For 133th epoch: test loss: 1.327 \n",
      "For 134th epoch: train accuracy: 65.000 \n",
      "For 134th epoch: test accuracy: 72.656 \n",
      "For 134th epoch: train loss: 0.166 \n",
      "For 134th epoch: test loss: 1.327 \n",
      "For 135th epoch: train accuracy: 66.000 \n",
      "For 135th epoch: test accuracy: 72.656 \n",
      "For 135th epoch: train loss: 0.162 \n",
      "For 135th epoch: test loss: 1.327 \n",
      "For 136th epoch: train accuracy: 63.000 \n",
      "For 136th epoch: test accuracy: 72.656 \n",
      "For 136th epoch: train loss: 0.176 \n",
      "For 136th epoch: test loss: 1.327 \n",
      "For 137th epoch: train accuracy: 60.000 \n",
      "For 137th epoch: test accuracy: 72.656 \n",
      "For 137th epoch: train loss: 0.190 \n",
      "For 137th epoch: test loss: 1.327 \n",
      "For 138th epoch: train accuracy: 66.000 \n",
      "For 138th epoch: test accuracy: 72.656 \n",
      "For 138th epoch: train loss: 0.162 \n",
      "For 138th epoch: test loss: 1.327 \n",
      "For 139th epoch: train accuracy: 66.000 \n",
      "For 139th epoch: test accuracy: 72.656 \n",
      "For 139th epoch: train loss: 0.161 \n",
      "For 139th epoch: test loss: 1.327 \n",
      "For 140th epoch: train accuracy: 66.000 \n",
      "For 140th epoch: test accuracy: 72.656 \n",
      "For 140th epoch: train loss: 0.162 \n",
      "For 140th epoch: test loss: 1.327 \n",
      "For 141th epoch: train accuracy: 66.000 \n",
      "For 141th epoch: test accuracy: 72.656 \n",
      "For 141th epoch: train loss: 0.162 \n",
      "For 141th epoch: test loss: 1.327 \n",
      "For 142th epoch: train accuracy: 71.000 \n",
      "For 142th epoch: test accuracy: 72.656 \n",
      "For 142th epoch: train loss: 0.138 \n",
      "For 142th epoch: test loss: 1.327 \n",
      "For 143th epoch: train accuracy: 67.000 \n",
      "For 143th epoch: test accuracy: 72.656 \n",
      "For 143th epoch: train loss: 0.157 \n",
      "For 143th epoch: test loss: 1.327 \n",
      "For 144th epoch: train accuracy: 64.000 \n",
      "For 144th epoch: test accuracy: 72.656 \n",
      "For 144th epoch: train loss: 0.172 \n",
      "For 144th epoch: test loss: 1.327 \n",
      "For 145th epoch: train accuracy: 65.000 \n",
      "For 145th epoch: test accuracy: 72.656 \n",
      "For 145th epoch: train loss: 0.166 \n",
      "For 145th epoch: test loss: 1.327 \n",
      "For 146th epoch: train accuracy: 68.000 \n",
      "For 146th epoch: test accuracy: 72.656 \n",
      "For 146th epoch: train loss: 0.152 \n",
      "For 146th epoch: test loss: 1.327 \n",
      "For 147th epoch: train accuracy: 74.000 \n",
      "For 147th epoch: test accuracy: 72.656 \n",
      "For 147th epoch: train loss: 0.124 \n",
      "For 147th epoch: test loss: 1.327 \n",
      "For 148th epoch: train accuracy: 64.000 \n",
      "For 148th epoch: test accuracy: 72.656 \n",
      "For 148th epoch: train loss: 0.172 \n",
      "For 148th epoch: test loss: 1.327 \n",
      "For 149th epoch: train accuracy: 71.000 \n",
      "For 149th epoch: test accuracy: 72.656 \n",
      "For 149th epoch: train loss: 0.138 \n",
      "For 149th epoch: test loss: 1.327 \n",
      "For 150th epoch: train accuracy: 75.000 \n",
      "For 150th epoch: test accuracy: 72.656 \n",
      "For 150th epoch: train loss: 0.119 \n",
      "For 150th epoch: test loss: 1.327 \n",
      "For 151th epoch: train accuracy: 67.000 \n",
      "For 151th epoch: test accuracy: 72.656 \n",
      "For 151th epoch: train loss: 0.157 \n",
      "For 151th epoch: test loss: 1.327 \n",
      "For 152th epoch: train accuracy: 67.000 \n",
      "For 152th epoch: test accuracy: 72.656 \n",
      "For 152th epoch: train loss: 0.157 \n",
      "For 152th epoch: test loss: 1.327 \n",
      "For 153th epoch: train accuracy: 67.000 \n",
      "For 153th epoch: test accuracy: 72.656 \n",
      "For 153th epoch: train loss: 0.157 \n",
      "For 153th epoch: test loss: 1.327 \n",
      "For 154th epoch: train accuracy: 72.000 \n",
      "For 154th epoch: test accuracy: 72.656 \n",
      "For 154th epoch: train loss: 0.133 \n",
      "For 154th epoch: test loss: 1.327 \n",
      "For 155th epoch: train accuracy: 61.000 \n",
      "For 155th epoch: test accuracy: 72.656 \n",
      "For 155th epoch: train loss: 0.186 \n",
      "For 155th epoch: test loss: 1.327 \n",
      "For 156th epoch: train accuracy: 63.000 \n",
      "For 156th epoch: test accuracy: 72.656 \n",
      "For 156th epoch: train loss: 0.176 \n",
      "For 156th epoch: test loss: 1.327 \n",
      "For 157th epoch: train accuracy: 67.000 \n",
      "For 157th epoch: test accuracy: 72.656 \n",
      "For 157th epoch: train loss: 0.157 \n",
      "For 157th epoch: test loss: 1.327 \n",
      "For 158th epoch: train accuracy: 70.000 \n",
      "For 158th epoch: test accuracy: 72.656 \n",
      "For 158th epoch: train loss: 0.143 \n",
      "For 158th epoch: test loss: 1.327 \n",
      "For 159th epoch: train accuracy: 75.000 \n",
      "For 159th epoch: test accuracy: 72.656 \n",
      "For 159th epoch: train loss: 0.119 \n",
      "For 159th epoch: test loss: 1.327 \n",
      "For 160th epoch: train accuracy: 71.000 \n",
      "For 160th epoch: test accuracy: 72.656 \n",
      "For 160th epoch: train loss: 0.138 \n",
      "For 160th epoch: test loss: 1.327 \n",
      "For 161th epoch: train accuracy: 73.000 \n",
      "For 161th epoch: test accuracy: 72.656 \n",
      "For 161th epoch: train loss: 0.128 \n",
      "For 161th epoch: test loss: 1.327 \n",
      "For 162th epoch: train accuracy: 56.000 \n",
      "For 162th epoch: test accuracy: 72.656 \n",
      "For 162th epoch: train loss: 0.209 \n",
      "For 162th epoch: test loss: 1.327 \n",
      "For 163th epoch: train accuracy: 68.000 \n",
      "For 163th epoch: test accuracy: 72.656 \n",
      "For 163th epoch: train loss: 0.152 \n",
      "For 163th epoch: test loss: 1.327 \n",
      "For 164th epoch: train accuracy: 75.000 \n",
      "For 164th epoch: test accuracy: 72.656 \n",
      "For 164th epoch: train loss: 0.119 \n",
      "For 164th epoch: test loss: 1.327 \n",
      "For 165th epoch: train accuracy: 64.000 \n",
      "For 165th epoch: test accuracy: 72.656 \n",
      "For 165th epoch: train loss: 0.171 \n",
      "For 165th epoch: test loss: 1.327 \n",
      "For 166th epoch: train accuracy: 68.000 \n",
      "For 166th epoch: test accuracy: 72.656 \n",
      "For 166th epoch: train loss: 0.153 \n",
      "For 166th epoch: test loss: 1.327 \n",
      "For 167th epoch: train accuracy: 71.000 \n",
      "For 167th epoch: test accuracy: 72.656 \n",
      "For 167th epoch: train loss: 0.138 \n",
      "For 167th epoch: test loss: 1.327 \n",
      "For 168th epoch: train accuracy: 60.000 \n",
      "For 168th epoch: test accuracy: 72.656 \n",
      "For 168th epoch: train loss: 0.190 \n",
      "For 168th epoch: test loss: 1.327 \n",
      "For 169th epoch: train accuracy: 63.000 \n",
      "For 169th epoch: test accuracy: 72.656 \n",
      "For 169th epoch: train loss: 0.176 \n",
      "For 169th epoch: test loss: 1.327 \n",
      "For 170th epoch: train accuracy: 70.000 \n",
      "For 170th epoch: test accuracy: 72.656 \n",
      "For 170th epoch: train loss: 0.143 \n",
      "For 170th epoch: test loss: 1.327 \n",
      "For 171th epoch: train accuracy: 70.000 \n",
      "For 171th epoch: test accuracy: 72.656 \n",
      "For 171th epoch: train loss: 0.142 \n",
      "For 171th epoch: test loss: 1.327 \n",
      "For 172th epoch: train accuracy: 66.000 \n",
      "For 172th epoch: test accuracy: 72.656 \n",
      "For 172th epoch: train loss: 0.162 \n",
      "For 172th epoch: test loss: 1.327 \n",
      "For 173th epoch: train accuracy: 66.000 \n",
      "For 173th epoch: test accuracy: 72.656 \n",
      "For 173th epoch: train loss: 0.161 \n",
      "For 173th epoch: test loss: 1.327 \n",
      "For 174th epoch: train accuracy: 74.000 \n",
      "For 174th epoch: test accuracy: 72.656 \n",
      "For 174th epoch: train loss: 0.124 \n",
      "For 174th epoch: test loss: 1.327 \n",
      "For 175th epoch: train accuracy: 71.000 \n",
      "For 175th epoch: test accuracy: 72.656 \n",
      "For 175th epoch: train loss: 0.138 \n",
      "For 175th epoch: test loss: 1.327 \n",
      "For 176th epoch: train accuracy: 68.000 \n",
      "For 176th epoch: test accuracy: 72.656 \n",
      "For 176th epoch: train loss: 0.152 \n",
      "For 176th epoch: test loss: 1.327 \n",
      "For 177th epoch: train accuracy: 70.000 \n",
      "For 177th epoch: test accuracy: 72.656 \n",
      "For 177th epoch: train loss: 0.143 \n",
      "For 177th epoch: test loss: 1.327 \n",
      "For 178th epoch: train accuracy: 74.000 \n",
      "For 178th epoch: test accuracy: 72.656 \n",
      "For 178th epoch: train loss: 0.124 \n",
      "For 178th epoch: test loss: 1.327 \n",
      "For 179th epoch: train accuracy: 75.000 \n",
      "For 179th epoch: test accuracy: 72.656 \n",
      "For 179th epoch: train loss: 0.119 \n",
      "For 179th epoch: test loss: 1.327 \n",
      "For 180th epoch: train accuracy: 68.000 \n",
      "For 180th epoch: test accuracy: 72.656 \n",
      "For 180th epoch: train loss: 0.152 \n",
      "For 180th epoch: test loss: 1.327 \n",
      "For 181th epoch: train accuracy: 70.000 \n",
      "For 181th epoch: test accuracy: 72.656 \n",
      "For 181th epoch: train loss: 0.143 \n",
      "For 181th epoch: test loss: 1.327 \n",
      "For 182th epoch: train accuracy: 66.000 \n",
      "For 182th epoch: test accuracy: 72.656 \n",
      "For 182th epoch: train loss: 0.162 \n",
      "For 182th epoch: test loss: 1.327 \n",
      "For 183th epoch: train accuracy: 63.000 \n",
      "For 183th epoch: test accuracy: 72.656 \n",
      "For 183th epoch: train loss: 0.176 \n",
      "For 183th epoch: test loss: 1.327 \n",
      "For 184th epoch: train accuracy: 71.000 \n",
      "For 184th epoch: test accuracy: 72.656 \n",
      "For 184th epoch: train loss: 0.138 \n",
      "For 184th epoch: test loss: 1.327 \n",
      "For 185th epoch: train accuracy: 63.000 \n",
      "For 185th epoch: test accuracy: 72.656 \n",
      "For 185th epoch: train loss: 0.176 \n",
      "For 185th epoch: test loss: 1.327 \n",
      "For 186th epoch: train accuracy: 64.000 \n",
      "For 186th epoch: test accuracy: 72.656 \n",
      "For 186th epoch: train loss: 0.172 \n",
      "For 186th epoch: test loss: 1.327 \n",
      "For 187th epoch: train accuracy: 76.000 \n",
      "For 187th epoch: test accuracy: 72.656 \n",
      "For 187th epoch: train loss: 0.114 \n",
      "For 187th epoch: test loss: 1.327 \n",
      "For 188th epoch: train accuracy: 66.000 \n",
      "For 188th epoch: test accuracy: 72.656 \n",
      "For 188th epoch: train loss: 0.162 \n",
      "For 188th epoch: test loss: 1.327 \n",
      "For 189th epoch: train accuracy: 68.000 \n",
      "For 189th epoch: test accuracy: 72.656 \n",
      "For 189th epoch: train loss: 0.153 \n",
      "For 189th epoch: test loss: 1.327 \n",
      "For 190th epoch: train accuracy: 75.000 \n",
      "For 190th epoch: test accuracy: 72.656 \n",
      "For 190th epoch: train loss: 0.119 \n",
      "For 190th epoch: test loss: 1.327 \n",
      "For 191th epoch: train accuracy: 66.000 \n",
      "For 191th epoch: test accuracy: 72.656 \n",
      "For 191th epoch: train loss: 0.162 \n",
      "For 191th epoch: test loss: 1.327 \n",
      "For 192th epoch: train accuracy: 67.000 \n",
      "For 192th epoch: test accuracy: 72.656 \n",
      "For 192th epoch: train loss: 0.157 \n",
      "For 192th epoch: test loss: 1.327 \n",
      "For 193th epoch: train accuracy: 72.000 \n",
      "For 193th epoch: test accuracy: 72.656 \n",
      "For 193th epoch: train loss: 0.133 \n",
      "For 193th epoch: test loss: 1.327 \n",
      "For 194th epoch: train accuracy: 74.000 \n",
      "For 194th epoch: test accuracy: 72.656 \n",
      "For 194th epoch: train loss: 0.123 \n",
      "For 194th epoch: test loss: 1.327 \n",
      "For 195th epoch: train accuracy: 73.000 \n",
      "For 195th epoch: test accuracy: 72.656 \n",
      "For 195th epoch: train loss: 0.128 \n",
      "For 195th epoch: test loss: 1.327 \n",
      "For 196th epoch: train accuracy: 65.000 \n",
      "For 196th epoch: test accuracy: 72.656 \n",
      "For 196th epoch: train loss: 0.167 \n",
      "For 196th epoch: test loss: 1.327 \n",
      "For 197th epoch: train accuracy: 67.000 \n",
      "For 197th epoch: test accuracy: 72.656 \n",
      "For 197th epoch: train loss: 0.157 \n",
      "For 197th epoch: test loss: 1.327 \n",
      "For 198th epoch: train accuracy: 64.000 \n",
      "For 198th epoch: test accuracy: 72.656 \n",
      "For 198th epoch: train loss: 0.171 \n",
      "For 198th epoch: test loss: 1.327 \n",
      "For 199th epoch: train accuracy: 65.000 \n",
      "For 199th epoch: test accuracy: 72.656 \n",
      "For 199th epoch: train loss: 0.166 \n",
      "For 199th epoch: test loss: 1.327 \n",
      "For 200th epoch: train accuracy: 65.000 \n",
      "For 200th epoch: test accuracy: 72.656 \n",
      "For 200th epoch: train loss: 0.167 \n",
      "For 200th epoch: test loss: 1.327 \n",
      "For 201th epoch: train accuracy: 76.000 \n",
      "For 201th epoch: test accuracy: 72.656 \n",
      "For 201th epoch: train loss: 0.114 \n",
      "For 201th epoch: test loss: 1.327 \n",
      "For 202th epoch: train accuracy: 62.000 \n",
      "For 202th epoch: test accuracy: 72.656 \n",
      "For 202th epoch: train loss: 0.181 \n",
      "For 202th epoch: test loss: 1.327 \n",
      "For 203th epoch: train accuracy: 61.000 \n",
      "For 203th epoch: test accuracy: 72.656 \n",
      "For 203th epoch: train loss: 0.186 \n",
      "For 203th epoch: test loss: 1.327 \n",
      "For 204th epoch: train accuracy: 64.000 \n",
      "For 204th epoch: test accuracy: 72.656 \n",
      "For 204th epoch: train loss: 0.171 \n",
      "For 204th epoch: test loss: 1.327 \n",
      "For 205th epoch: train accuracy: 65.000 \n",
      "For 205th epoch: test accuracy: 72.656 \n",
      "For 205th epoch: train loss: 0.166 \n",
      "For 205th epoch: test loss: 1.327 \n",
      "For 206th epoch: train accuracy: 66.000 \n",
      "For 206th epoch: test accuracy: 72.656 \n",
      "For 206th epoch: train loss: 0.162 \n",
      "For 206th epoch: test loss: 1.327 \n",
      "For 207th epoch: train accuracy: 62.000 \n",
      "For 207th epoch: test accuracy: 72.656 \n",
      "For 207th epoch: train loss: 0.181 \n",
      "For 207th epoch: test loss: 1.327 \n",
      "For 208th epoch: train accuracy: 60.000 \n",
      "For 208th epoch: test accuracy: 72.656 \n",
      "For 208th epoch: train loss: 0.190 \n",
      "For 208th epoch: test loss: 1.327 \n",
      "For 209th epoch: train accuracy: 67.000 \n",
      "For 209th epoch: test accuracy: 72.656 \n",
      "For 209th epoch: train loss: 0.157 \n",
      "For 209th epoch: test loss: 1.327 \n",
      "For 210th epoch: train accuracy: 65.000 \n",
      "For 210th epoch: test accuracy: 72.656 \n",
      "For 210th epoch: train loss: 0.166 \n",
      "For 210th epoch: test loss: 1.327 \n",
      "For 211th epoch: train accuracy: 67.000 \n",
      "For 211th epoch: test accuracy: 72.656 \n",
      "For 211th epoch: train loss: 0.157 \n",
      "For 211th epoch: test loss: 1.327 \n",
      "For 212th epoch: train accuracy: 50.000 \n",
      "For 212th epoch: test accuracy: 72.656 \n",
      "For 212th epoch: train loss: 0.238 \n",
      "For 212th epoch: test loss: 1.327 \n",
      "For 213th epoch: train accuracy: 62.000 \n",
      "For 213th epoch: test accuracy: 72.656 \n",
      "For 213th epoch: train loss: 0.181 \n",
      "For 213th epoch: test loss: 1.327 \n",
      "For 214th epoch: train accuracy: 66.000 \n",
      "For 214th epoch: test accuracy: 72.656 \n",
      "For 214th epoch: train loss: 0.162 \n",
      "For 214th epoch: test loss: 1.327 \n",
      "For 215th epoch: train accuracy: 66.000 \n",
      "For 215th epoch: test accuracy: 72.656 \n",
      "For 215th epoch: train loss: 0.162 \n",
      "For 215th epoch: test loss: 1.327 \n",
      "For 216th epoch: train accuracy: 65.000 \n",
      "For 216th epoch: test accuracy: 72.656 \n",
      "For 216th epoch: train loss: 0.167 \n",
      "For 216th epoch: test loss: 1.327 \n",
      "For 217th epoch: train accuracy: 65.000 \n",
      "For 217th epoch: test accuracy: 72.656 \n",
      "For 217th epoch: train loss: 0.166 \n",
      "For 217th epoch: test loss: 1.327 \n",
      "For 218th epoch: train accuracy: 73.000 \n",
      "For 218th epoch: test accuracy: 72.656 \n",
      "For 218th epoch: train loss: 0.128 \n",
      "For 218th epoch: test loss: 1.327 \n",
      "For 219th epoch: train accuracy: 68.000 \n",
      "For 219th epoch: test accuracy: 72.656 \n",
      "For 219th epoch: train loss: 0.152 \n",
      "For 219th epoch: test loss: 1.327 \n",
      "For 220th epoch: train accuracy: 71.000 \n",
      "For 220th epoch: test accuracy: 72.656 \n",
      "For 220th epoch: train loss: 0.138 \n",
      "For 220th epoch: test loss: 1.327 \n",
      "For 221th epoch: train accuracy: 62.000 \n",
      "For 221th epoch: test accuracy: 72.656 \n",
      "For 221th epoch: train loss: 0.181 \n",
      "For 221th epoch: test loss: 1.327 \n",
      "For 222th epoch: train accuracy: 73.000 \n",
      "For 222th epoch: test accuracy: 72.656 \n",
      "For 222th epoch: train loss: 0.129 \n",
      "For 222th epoch: test loss: 1.327 \n",
      "For 223th epoch: train accuracy: 75.000 \n",
      "For 223th epoch: test accuracy: 72.656 \n",
      "For 223th epoch: train loss: 0.119 \n",
      "For 223th epoch: test loss: 1.327 \n",
      "For 224th epoch: train accuracy: 65.000 \n",
      "For 224th epoch: test accuracy: 72.656 \n",
      "For 224th epoch: train loss: 0.166 \n",
      "For 224th epoch: test loss: 1.327 \n",
      "For 225th epoch: train accuracy: 68.000 \n",
      "For 225th epoch: test accuracy: 72.656 \n",
      "For 225th epoch: train loss: 0.152 \n",
      "For 225th epoch: test loss: 1.327 \n",
      "For 226th epoch: train accuracy: 65.000 \n",
      "For 226th epoch: test accuracy: 72.656 \n",
      "For 226th epoch: train loss: 0.167 \n",
      "For 226th epoch: test loss: 1.327 \n",
      "For 227th epoch: train accuracy: 70.000 \n",
      "For 227th epoch: test accuracy: 72.656 \n",
      "For 227th epoch: train loss: 0.143 \n",
      "For 227th epoch: test loss: 1.327 \n",
      "For 228th epoch: train accuracy: 65.000 \n",
      "For 228th epoch: test accuracy: 72.656 \n",
      "For 228th epoch: train loss: 0.167 \n",
      "For 228th epoch: test loss: 1.327 \n",
      "For 229th epoch: train accuracy: 76.000 \n",
      "For 229th epoch: test accuracy: 72.656 \n",
      "For 229th epoch: train loss: 0.114 \n",
      "For 229th epoch: test loss: 1.327 \n",
      "For 230th epoch: train accuracy: 65.000 \n",
      "For 230th epoch: test accuracy: 72.656 \n",
      "For 230th epoch: train loss: 0.166 \n",
      "For 230th epoch: test loss: 1.327 \n",
      "For 231th epoch: train accuracy: 71.000 \n",
      "For 231th epoch: test accuracy: 72.656 \n",
      "For 231th epoch: train loss: 0.138 \n",
      "For 231th epoch: test loss: 1.327 \n",
      "For 232th epoch: train accuracy: 69.000 \n",
      "For 232th epoch: test accuracy: 72.656 \n",
      "For 232th epoch: train loss: 0.148 \n",
      "For 232th epoch: test loss: 1.327 \n",
      "For 233th epoch: train accuracy: 66.000 \n",
      "For 233th epoch: test accuracy: 72.656 \n",
      "For 233th epoch: train loss: 0.162 \n",
      "For 233th epoch: test loss: 1.327 \n",
      "For 234th epoch: train accuracy: 69.000 \n",
      "For 234th epoch: test accuracy: 72.656 \n",
      "For 234th epoch: train loss: 0.147 \n",
      "For 234th epoch: test loss: 1.327 \n",
      "For 235th epoch: train accuracy: 61.000 \n",
      "For 235th epoch: test accuracy: 72.656 \n",
      "For 235th epoch: train loss: 0.186 \n",
      "For 235th epoch: test loss: 1.327 \n",
      "For 236th epoch: train accuracy: 73.000 \n",
      "For 236th epoch: test accuracy: 72.656 \n",
      "For 236th epoch: train loss: 0.128 \n",
      "For 236th epoch: test loss: 1.327 \n",
      "For 237th epoch: train accuracy: 70.000 \n",
      "For 237th epoch: test accuracy: 72.656 \n",
      "For 237th epoch: train loss: 0.143 \n",
      "For 237th epoch: test loss: 1.327 \n",
      "For 238th epoch: train accuracy: 71.000 \n",
      "For 238th epoch: test accuracy: 72.656 \n",
      "For 238th epoch: train loss: 0.138 \n",
      "For 238th epoch: test loss: 1.327 \n",
      "For 239th epoch: train accuracy: 60.000 \n",
      "For 239th epoch: test accuracy: 72.656 \n",
      "For 239th epoch: train loss: 0.190 \n",
      "For 239th epoch: test loss: 1.327 \n",
      "For 240th epoch: train accuracy: 67.000 \n",
      "For 240th epoch: test accuracy: 72.656 \n",
      "For 240th epoch: train loss: 0.157 \n",
      "For 240th epoch: test loss: 1.327 \n",
      "For 241th epoch: train accuracy: 69.000 \n",
      "For 241th epoch: test accuracy: 72.656 \n",
      "For 241th epoch: train loss: 0.147 \n",
      "For 241th epoch: test loss: 1.327 \n",
      "For 242th epoch: train accuracy: 68.000 \n",
      "For 242th epoch: test accuracy: 72.656 \n",
      "For 242th epoch: train loss: 0.152 \n",
      "For 242th epoch: test loss: 1.327 \n",
      "For 243th epoch: train accuracy: 59.000 \n",
      "For 243th epoch: test accuracy: 72.656 \n",
      "For 243th epoch: train loss: 0.195 \n",
      "For 243th epoch: test loss: 1.327 \n",
      "For 244th epoch: train accuracy: 64.000 \n",
      "For 244th epoch: test accuracy: 72.656 \n",
      "For 244th epoch: train loss: 0.171 \n",
      "For 244th epoch: test loss: 1.327 \n",
      "For 245th epoch: train accuracy: 71.000 \n",
      "For 245th epoch: test accuracy: 72.656 \n",
      "For 245th epoch: train loss: 0.138 \n",
      "For 245th epoch: test loss: 1.327 \n",
      "For 246th epoch: train accuracy: 63.000 \n",
      "For 246th epoch: test accuracy: 72.656 \n",
      "For 246th epoch: train loss: 0.176 \n",
      "For 246th epoch: test loss: 1.327 \n",
      "For 247th epoch: train accuracy: 73.000 \n",
      "For 247th epoch: test accuracy: 72.656 \n",
      "For 247th epoch: train loss: 0.128 \n",
      "For 247th epoch: test loss: 1.327 \n",
      "For 248th epoch: train accuracy: 67.000 \n",
      "For 248th epoch: test accuracy: 72.656 \n",
      "For 248th epoch: train loss: 0.157 \n",
      "For 248th epoch: test loss: 1.327 \n",
      "For 249th epoch: train accuracy: 66.000 \n",
      "For 249th epoch: test accuracy: 72.656 \n",
      "For 249th epoch: train loss: 0.162 \n",
      "For 249th epoch: test loss: 1.327 \n",
      "For 250th epoch: train accuracy: 65.000 \n",
      "For 250th epoch: test accuracy: 72.656 \n",
      "For 250th epoch: train loss: 0.166 \n",
      "For 250th epoch: test loss: 1.327 \n",
      "For 251th epoch: train accuracy: 64.000 \n",
      "For 251th epoch: test accuracy: 72.656 \n",
      "For 251th epoch: train loss: 0.171 \n",
      "For 251th epoch: test loss: 1.327 \n",
      "For 252th epoch: train accuracy: 76.000 \n",
      "For 252th epoch: test accuracy: 72.656 \n",
      "For 252th epoch: train loss: 0.114 \n",
      "For 252th epoch: test loss: 1.327 \n",
      "For 253th epoch: train accuracy: 66.000 \n",
      "For 253th epoch: test accuracy: 72.656 \n",
      "For 253th epoch: train loss: 0.162 \n",
      "For 253th epoch: test loss: 1.327 \n",
      "For 254th epoch: train accuracy: 76.000 \n",
      "For 254th epoch: test accuracy: 72.656 \n",
      "For 254th epoch: train loss: 0.114 \n",
      "For 254th epoch: test loss: 1.327 \n",
      "For 255th epoch: train accuracy: 80.000 \n",
      "For 255th epoch: test accuracy: 72.656 \n",
      "For 255th epoch: train loss: 0.095 \n",
      "For 255th epoch: test loss: 1.327 \n",
      "For 256th epoch: train accuracy: 72.000 \n",
      "For 256th epoch: test accuracy: 72.656 \n",
      "For 256th epoch: train loss: 0.133 \n",
      "For 256th epoch: test loss: 1.327 \n",
      "For 257th epoch: train accuracy: 71.000 \n",
      "For 257th epoch: test accuracy: 72.656 \n",
      "For 257th epoch: train loss: 0.138 \n",
      "For 257th epoch: test loss: 1.327 \n",
      "For 258th epoch: train accuracy: 76.000 \n",
      "For 258th epoch: test accuracy: 72.656 \n",
      "For 258th epoch: train loss: 0.114 \n",
      "For 258th epoch: test loss: 1.327 \n",
      "For 259th epoch: train accuracy: 72.000 \n",
      "For 259th epoch: test accuracy: 72.656 \n",
      "For 259th epoch: train loss: 0.133 \n",
      "For 259th epoch: test loss: 1.327 \n",
      "For 260th epoch: train accuracy: 61.000 \n",
      "For 260th epoch: test accuracy: 72.656 \n",
      "For 260th epoch: train loss: 0.186 \n",
      "For 260th epoch: test loss: 1.327 \n",
      "For 261th epoch: train accuracy: 71.000 \n",
      "For 261th epoch: test accuracy: 72.656 \n",
      "For 261th epoch: train loss: 0.138 \n",
      "For 261th epoch: test loss: 1.327 \n",
      "For 262th epoch: train accuracy: 66.000 \n",
      "For 262th epoch: test accuracy: 72.656 \n",
      "For 262th epoch: train loss: 0.162 \n",
      "For 262th epoch: test loss: 1.327 \n",
      "For 263th epoch: train accuracy: 73.000 \n",
      "For 263th epoch: test accuracy: 72.656 \n",
      "For 263th epoch: train loss: 0.129 \n",
      "For 263th epoch: test loss: 1.327 \n",
      "For 264th epoch: train accuracy: 64.000 \n",
      "For 264th epoch: test accuracy: 72.656 \n",
      "For 264th epoch: train loss: 0.172 \n",
      "For 264th epoch: test loss: 1.327 \n",
      "For 265th epoch: train accuracy: 67.000 \n",
      "For 265th epoch: test accuracy: 72.656 \n",
      "For 265th epoch: train loss: 0.157 \n",
      "For 265th epoch: test loss: 1.327 \n",
      "For 266th epoch: train accuracy: 69.000 \n",
      "For 266th epoch: test accuracy: 72.656 \n",
      "For 266th epoch: train loss: 0.147 \n",
      "For 266th epoch: test loss: 1.327 \n",
      "For 267th epoch: train accuracy: 65.000 \n",
      "For 267th epoch: test accuracy: 72.656 \n",
      "For 267th epoch: train loss: 0.167 \n",
      "For 267th epoch: test loss: 1.327 \n",
      "For 268th epoch: train accuracy: 63.000 \n",
      "For 268th epoch: test accuracy: 72.656 \n",
      "For 268th epoch: train loss: 0.176 \n",
      "For 268th epoch: test loss: 1.327 \n",
      "For 269th epoch: train accuracy: 68.000 \n",
      "For 269th epoch: test accuracy: 72.656 \n",
      "For 269th epoch: train loss: 0.152 \n",
      "For 269th epoch: test loss: 1.327 \n",
      "For 270th epoch: train accuracy: 60.000 \n",
      "For 270th epoch: test accuracy: 72.656 \n",
      "For 270th epoch: train loss: 0.190 \n",
      "For 270th epoch: test loss: 1.327 \n",
      "For 271th epoch: train accuracy: 68.000 \n",
      "For 271th epoch: test accuracy: 72.656 \n",
      "For 271th epoch: train loss: 0.153 \n",
      "For 271th epoch: test loss: 1.327 \n",
      "For 272th epoch: train accuracy: 69.000 \n",
      "For 272th epoch: test accuracy: 72.656 \n",
      "For 272th epoch: train loss: 0.147 \n",
      "For 272th epoch: test loss: 1.327 \n",
      "For 273th epoch: train accuracy: 67.000 \n",
      "For 273th epoch: test accuracy: 72.656 \n",
      "For 273th epoch: train loss: 0.157 \n",
      "For 273th epoch: test loss: 1.327 \n",
      "For 274th epoch: train accuracy: 66.000 \n",
      "For 274th epoch: test accuracy: 72.656 \n",
      "For 274th epoch: train loss: 0.161 \n",
      "For 274th epoch: test loss: 1.327 \n",
      "For 275th epoch: train accuracy: 72.000 \n",
      "For 275th epoch: test accuracy: 72.656 \n",
      "For 275th epoch: train loss: 0.133 \n",
      "For 275th epoch: test loss: 1.327 \n",
      "For 276th epoch: train accuracy: 61.000 \n",
      "For 276th epoch: test accuracy: 72.656 \n",
      "For 276th epoch: train loss: 0.186 \n",
      "For 276th epoch: test loss: 1.327 \n",
      "For 277th epoch: train accuracy: 72.000 \n",
      "For 277th epoch: test accuracy: 72.656 \n",
      "For 277th epoch: train loss: 0.133 \n",
      "For 277th epoch: test loss: 1.327 \n",
      "For 278th epoch: train accuracy: 60.000 \n",
      "For 278th epoch: test accuracy: 72.656 \n",
      "For 278th epoch: train loss: 0.190 \n",
      "For 278th epoch: test loss: 1.327 \n",
      "For 279th epoch: train accuracy: 62.000 \n",
      "For 279th epoch: test accuracy: 72.656 \n",
      "For 279th epoch: train loss: 0.181 \n",
      "For 279th epoch: test loss: 1.327 \n",
      "For 280th epoch: train accuracy: 63.000 \n",
      "For 280th epoch: test accuracy: 72.656 \n",
      "For 280th epoch: train loss: 0.176 \n",
      "For 280th epoch: test loss: 1.327 \n",
      "For 281th epoch: train accuracy: 66.000 \n",
      "For 281th epoch: test accuracy: 72.656 \n",
      "For 281th epoch: train loss: 0.162 \n",
      "For 281th epoch: test loss: 1.327 \n",
      "For 282th epoch: train accuracy: 76.000 \n",
      "For 282th epoch: test accuracy: 72.656 \n",
      "For 282th epoch: train loss: 0.114 \n",
      "For 282th epoch: test loss: 1.327 \n",
      "For 283th epoch: train accuracy: 65.000 \n",
      "For 283th epoch: test accuracy: 72.656 \n",
      "For 283th epoch: train loss: 0.167 \n",
      "For 283th epoch: test loss: 1.327 \n",
      "For 284th epoch: train accuracy: 74.000 \n",
      "For 284th epoch: test accuracy: 72.656 \n",
      "For 284th epoch: train loss: 0.124 \n",
      "For 284th epoch: test loss: 1.327 \n",
      "For 285th epoch: train accuracy: 66.000 \n",
      "For 285th epoch: test accuracy: 72.656 \n",
      "For 285th epoch: train loss: 0.162 \n",
      "For 285th epoch: test loss: 1.327 \n",
      "For 286th epoch: train accuracy: 64.000 \n",
      "For 286th epoch: test accuracy: 72.656 \n",
      "For 286th epoch: train loss: 0.171 \n",
      "For 286th epoch: test loss: 1.327 \n",
      "For 287th epoch: train accuracy: 73.000 \n",
      "For 287th epoch: test accuracy: 72.656 \n",
      "For 287th epoch: train loss: 0.128 \n",
      "For 287th epoch: test loss: 1.327 \n",
      "For 288th epoch: train accuracy: 67.000 \n",
      "For 288th epoch: test accuracy: 72.656 \n",
      "For 288th epoch: train loss: 0.157 \n",
      "For 288th epoch: test loss: 1.327 \n",
      "For 289th epoch: train accuracy: 59.000 \n",
      "For 289th epoch: test accuracy: 72.656 \n",
      "For 289th epoch: train loss: 0.195 \n",
      "For 289th epoch: test loss: 1.327 \n",
      "For 290th epoch: train accuracy: 71.000 \n",
      "For 290th epoch: test accuracy: 72.656 \n",
      "For 290th epoch: train loss: 0.138 \n",
      "For 290th epoch: test loss: 1.327 \n",
      "For 291th epoch: train accuracy: 68.000 \n",
      "For 291th epoch: test accuracy: 72.656 \n",
      "For 291th epoch: train loss: 0.152 \n",
      "For 291th epoch: test loss: 1.327 \n",
      "For 292th epoch: train accuracy: 65.000 \n",
      "For 292th epoch: test accuracy: 72.656 \n",
      "For 292th epoch: train loss: 0.167 \n",
      "For 292th epoch: test loss: 1.327 \n",
      "For 293th epoch: train accuracy: 64.000 \n",
      "For 293th epoch: test accuracy: 72.656 \n",
      "For 293th epoch: train loss: 0.171 \n",
      "For 293th epoch: test loss: 1.327 \n",
      "For 294th epoch: train accuracy: 61.000 \n",
      "For 294th epoch: test accuracy: 72.656 \n",
      "For 294th epoch: train loss: 0.186 \n",
      "For 294th epoch: test loss: 1.327 \n",
      "For 295th epoch: train accuracy: 75.000 \n",
      "For 295th epoch: test accuracy: 72.656 \n",
      "For 295th epoch: train loss: 0.119 \n",
      "For 295th epoch: test loss: 1.327 \n",
      "For 296th epoch: train accuracy: 65.000 \n",
      "For 296th epoch: test accuracy: 72.656 \n",
      "For 296th epoch: train loss: 0.167 \n",
      "For 296th epoch: test loss: 1.327 \n",
      "For 297th epoch: train accuracy: 63.000 \n",
      "For 297th epoch: test accuracy: 72.656 \n",
      "For 297th epoch: train loss: 0.176 \n",
      "For 297th epoch: test loss: 1.327 \n",
      "For 298th epoch: train accuracy: 71.000 \n",
      "For 298th epoch: test accuracy: 72.656 \n",
      "For 298th epoch: train loss: 0.138 \n",
      "For 298th epoch: test loss: 1.327 \n",
      "For 299th epoch: train accuracy: 76.000 \n",
      "For 299th epoch: test accuracy: 72.656 \n",
      "For 299th epoch: train loss: 0.114 \n",
      "For 299th epoch: test loss: 1.327 \n"
     ]
    }
   ],
   "source": [
    "epochs=300\n",
    "lr=0.001\n",
    "batch=100\n",
    "\n",
    "losses,accuracies,test_accuracies=[],[],[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    sample=np.random.randint(0,x_train.shape[0],size=(batch))\n",
    "    x=x_train[sample]\n",
    "    y=y_train[sample]\n",
    " \n",
    "\n",
    "    out,w1_updated,w2_updated =forward_backward_pass(x,y,lr)\n",
    "  \n",
    "    category=np.argmax(out,axis=1)\n",
    "    accuracy=(category==y).mean()\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    train_loss= cross_entropy(y,out)\n",
    "    train_loss = train_loss.mean()\n",
    "    losses.append(train_loss.item())\n",
    " \n",
    "    \n",
    "    y_pred=np.argmax(softmax(sigmoid(x_test.dot(w1_updated)).dot(w2_updated)),axis=1)\n",
    "    test_acc=(y_pred==y_test).mean()\n",
    "    test_accuracies.append(test_acc.item())\n",
    "    \n",
    "    y_pred2 = (softmax(sigmoid(x_test.dot(w1_updated)).dot(w2_updated)))\n",
    "    test_loss = cross_entropy(y_test,y_pred2)\n",
    "    test_loss = test_loss.mean()\n",
    "    \n",
    "    \n",
    "    print(f'For {i}th epoch: train accuracy: {accuracy*100:.3f} ')\n",
    "    print(f'For {i}th epoch: test accuracy: {test_acc*100:.3f} ')\n",
    "    print(f'For {i}th epoch: train loss: {train_loss:.3f} ')\n",
    "    print(f'For {i}th epoch: test loss: {test_loss:.3f} ')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yasme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "\n",
    "ecall = recall_score(y_test, y_pred, average='binary')\n",
    "\n",
    "f1_score = f1_score(y_test, y_pred, average='binary')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59d47c279002dece9369d3ec104f5194addc14c635d4801df159bd4deb836c57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
